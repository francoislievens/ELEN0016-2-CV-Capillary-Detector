{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b46a350",
   "metadata": {},
   "source": [
    "# Droplet and cells detector evaluator\n",
    "\n",
    "This notebook implemente our procedure to evaluate performances of our model to count and detect cells and droplets in the input videos by comparing predictions to the ground thruth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4139e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from ReadingBuffer import ReadingBuffer\n",
    "from MOG_Filter import MOG_filter\n",
    "from DropletDetector import DropletDetector\n",
    "from UNetBuffer import UNetBuffer\n",
    "from UNetThread import UNetThread\n",
    "from utils import convert_annot\n",
    "from utils import convert_pred\n",
    "from utils import get_result_idx\n",
    "\n",
    "DATA_PATH = 'Original_Dataset'\n",
    "OUTPUT_PATH = 'Output_Results'\n",
    "UNET_PATH = 'Model'\n",
    "UNET_NAME = 'UNet_A'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BUFFER_SIZE = 500\n",
    "\n",
    "# An array with the name of the videos to read\n",
    "input_files = ['CV2021_GROUP02', 'CV2021_GROUP03', 'CV2021_GROUP04']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3e486",
   "metadata": {},
   "source": [
    "# Prediction loop\n",
    "In this cell, we instanciate all elements of our model and we are making predictions itteratively for each given input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1729b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* -------------------------------------------- *\n",
      "* End of predictions for CV2021_GROUP02\n",
      "* Total readed frames: 1262\n",
      "* Detected droplets: 141\n",
      "* Detected cells: 39\n",
      "* Computing time: 10.298587322235107\n",
      "* Frames per second: 122.54107874342007\n",
      "* Histogram of the number of cell per droplet:\n",
      "*   - Droplets with 0 cells: 106.0\n",
      "*   - Droplets with 1 cells: 31.0\n",
      "*   - Droplets with 2 cells: 4.0\n",
      "*   - Droplets with 3 cells: 0.0\n",
      "*   - Droplets with 4 cells: 0.0\n",
      "*   - Droplets with 5 cells: 0.0\n",
      "*   - Droplets with 6 cells: 0.0\n",
      "*   - Droplets with 7 cells: 0.0\n",
      "*   - Droplets with 8 cells: 0.0\n",
      "*   - Droplets with 9 cells: 0.0\n",
      "* -------------------------------------------- *\n",
      "* End of predictions for CV2021_GROUP03\n",
      "* Total readed frames: 1267\n",
      "* Detected droplets: 181\n",
      "* Detected cells: 36\n",
      "* Computing time: 6.321088552474976\n",
      "* Frames per second: 200.44015986833716\n",
      "* Histogram of the number of cell per droplet:\n",
      "*   - Droplets with 0 cells: 147.0\n",
      "*   - Droplets with 1 cells: 32.0\n",
      "*   - Droplets with 2 cells: 2.0\n",
      "*   - Droplets with 3 cells: 0.0\n",
      "*   - Droplets with 4 cells: 0.0\n",
      "*   - Droplets with 5 cells: 0.0\n",
      "*   - Droplets with 6 cells: 0.0\n",
      "*   - Droplets with 7 cells: 0.0\n",
      "*   - Droplets with 8 cells: 0.0\n",
      "*   - Droplets with 9 cells: 0.0\n",
      "* -------------------------------------------- *\n",
      "* End of predictions for CV2021_GROUP04\n",
      "* Total readed frames: 1263\n",
      "* Detected droplets: 180\n",
      "* Detected cells: 36\n",
      "* Computing time: 6.102593183517456\n",
      "* Frames per second: 206.96119862802703\n",
      "* Histogram of the number of cell per droplet:\n",
      "*   - Droplets with 0 cells: 147.0\n",
      "*   - Droplets with 1 cells: 30.0\n",
      "*   - Droplets with 2 cells: 3.0\n",
      "*   - Droplets with 3 cells: 0.0\n",
      "*   - Droplets with 4 cells: 0.0\n",
      "*   - Droplets with 5 cells: 0.0\n",
      "*   - Droplets with 6 cells: 0.0\n",
      "*   - Droplets with 7 cells: 0.0\n",
      "*   - Droplets with 8 cells: 0.0\n",
      "*   - Droplets with 9 cells: 0.0\n"
     ]
    }
   ],
   "source": [
    "for input_name in input_files:\n",
    "    \n",
    "    # Get the group number and the video path\n",
    "    gp = int(input_name[-2:])\n",
    "    video_path = '{}/images/{}/group{}.mp4'.format(DATA_PATH, input_name, gp)\n",
    "    \n",
    "    # ================================================= #\n",
    "    #      Initialization of all components             #\n",
    "    # ================================================= #\n",
    "    \n",
    "    # Build the reading buffer\n",
    "    buff_read = ReadingBuffer(path_list=[video_path],\n",
    "                              buff_size=BUFFER_SIZE,\n",
    "                              device=DEVICE)\n",
    "    # The MOG filter thread\n",
    "    buff_mog = MOG_filter(input_buffer=buff_read,\n",
    "                          buff_size=BUFFER_SIZE,\n",
    "                          device=DEVICE)\n",
    "    # The Droplet detector/counter\n",
    "    buff_droplet = DropletDetector(input_buffer=buff_mog,\n",
    "                                   buff_size=BUFFER_SIZE,\n",
    "                                   device=DEVICE,\n",
    "                                   debug=False)\n",
    "\n",
    "    # A buffer for the UNet: do the tensorisation step\n",
    "    buff_UNet = UNetBuffer(input_buffer=buff_droplet,\n",
    "                           buff_size=BUFFER_SIZE,\n",
    "                           device=DEVICE,\n",
    "                           display=False)\n",
    "\n",
    "    # The UNet thread to count cells\n",
    "    UNet_thread = UNetThread(input_buffer=buff_UNet,\n",
    "                             model_path=UNET_PATH,\n",
    "                             model_name=UNET_NAME,\n",
    "                             device=DEVICE,\n",
    "                             batch_size=10,\n",
    "                             display=False)\n",
    "    start_time = time.time()\n",
    "    buff_read.start()\n",
    "    buff_mog.start()\n",
    "    buff_droplet.start()\n",
    "    buff_UNet.start()\n",
    "    UNet_thread.start()\n",
    "    \n",
    "    # ================================================= #\n",
    "    #                  Working Loop                     #\n",
    "    # ================================================= #\n",
    "    \n",
    "    while not UNet_thread.end:\n",
    "        # Wait the end of the predictions\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    # Get the execution time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # ================================================= #\n",
    "    #                  Export results                   #\n",
    "    # ================================================= #\n",
    "    \n",
    "    print('* -------------------------------------------- *')\n",
    "    print('* End of predictions for {}'.format(input_name))\n",
    "    print('* Total readed frames: {}'.format(buff_read.frame_idx))\n",
    "    print('* Detected droplets: {}'.format(buff_droplet.drop_counter))\n",
    "    print('* Detected cells: {}'.format(UNet_thread.total_cell))\n",
    "    print('* Computing time: {}'.format(end_time - start_time))\n",
    "    total_frame_idx = buff_read.frame_idx\n",
    "    print('* Frames per second: {}'.format(total_frame_idx / (end_time - start_time)))\n",
    "    \n",
    "    # We deduce the number of droplets without cell\n",
    "    nb_zero_cell = buff_droplet.drop_counter - sum(UNet_thread.histogram)\n",
    "    UNet_thread.histogram[0] = nb_zero_cell\n",
    "    # We build the histogram\n",
    "    histo = []\n",
    "    i = 0\n",
    "    print('* Histogram of the number of cell per droplet:')\n",
    "    for itm in UNet_thread.histogram.tolist():\n",
    "        histo.append(str(int(itm)))\n",
    "        print('*   - Droplets with {} cells: {}'.format(i, itm))\n",
    "        i += 1\n",
    "    \n",
    "    # Write it in the output file: \n",
    "    f = open('{}/{}_histo.csv'.format(OUTPUT_PATH, input_name), 'w')\n",
    "    f.write(','.join(histo))\n",
    "    f.close()\n",
    "    \n",
    "    # Export detected object coordinates\n",
    "    results_drp = buff_droplet.final_results\n",
    "    results_cell = UNet_thread.final_results\n",
    "    to_print = []\n",
    "    # Investigate all frame index\n",
    "    for i in range(0, total_frame_idx):\n",
    "        x_start = 0\n",
    "        finded = False\n",
    "        # Check if droplet at this index\n",
    "        for j in range(0, len(results_drp)):\n",
    "            if results_drp[j][0] == i:\n",
    "                to_print.append('frame_{},{},0,{},240,droplet'.format(i,\n",
    "                                                                        results_drp[j][1],\n",
    "                                                                        results_drp[j][2]))\n",
    "                x_start = results_drp[j][1]\n",
    "                finded = True\n",
    "                \n",
    "        # If we have a droplet at this frame, we check if cells are present\n",
    "        if finded: \n",
    "            for j in range(0, len(results_cell)):\n",
    "                if results_cell[j][0] == i:\n",
    "                    to_print.append('frame_{},{},{},{},{},cell'.format(i,\n",
    "                                                                         results_cell[j][2]-5+x_start,\n",
    "                                                                         results_cell[j][3]-5,\n",
    "                                                                         results_cell[j][2]+5+x_start,\n",
    "                                                                         results_cell[j][3]+5))\n",
    "    # Save in a file\n",
    "    f = open('{}/{}_track.csv'.format(OUTPUT_PATH, input_name), 'w')\n",
    "    f.write('\\n'.join(to_print))\n",
    "    f.close()\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1edfd",
   "metadata": {},
   "source": [
    "# Evaluation Step\n",
    "In the following cells, we will compare our predictions with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5f9cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Droplets results: \n",
      "*   - True positives: 3741\n",
      "*   - False positives: 43\n",
      "*   - False negatives: 4\n",
      "* Cells results: \n",
      "*   - True positives: 101\n",
      "*   - False positives: 0\n",
      "*   - False negatives: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drp_true_positive = 0\n",
    "drp_false_positive = 0\n",
    "drp_false_negative = 0\n",
    "cell_true_positive = 0\n",
    "cell_false_positive = 0\n",
    "cell_false_negative = 0\n",
    "\n",
    "for input_name in input_files:\n",
    "    \n",
    "    # Load predictions and annotations \n",
    "    preds = pd.read_csv('{}/{}_track.csv'.format(OUTPUT_PATH, input_name), header=None, sep=',')\n",
    "    annot = pd.read_csv('{}/annotations/{}/{}.csv'.format(DATA_PATH, input_name, input_name), sep=';')\n",
    "    # Sort the input by frame index order\n",
    "    annot = annot.sort_values(by=['Slice'], ascending=True, ignore_index=True)\n",
    "    \n",
    "    # ================================================= #\n",
    "    #               Annotations conversion              #\n",
    "    #  We transform the annotation file to the same     #\n",
    "    #  format that the prediction file:                 #\n",
    "    #    - Only consider full droplets (>250pxl width)  #\n",
    "    #    - Only keep the second view of the droplet     #\n",
    "    #    - Only keep cells of this droplets             #\n",
    "    # ================================================= #\n",
    "    max_slice = annot['Slice'].max()\n",
    "    once_seen_droplet = []\n",
    "    twice_seen_droplet = []\n",
    "    new_annot = []\n",
    "\n",
    "    for i in range(0, max_slice):\n",
    "        \n",
    "        # Get annotations at this frame index if exists and convert it in a working format\n",
    "        tmp = convert_annot(annot[annot['Slice'] == i])\n",
    "\n",
    "        if len(tmp) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Check if contain a droplet wider than 250pxl\n",
    "        for itm in tmp:\n",
    "            if itm [1] == 'droplet':\n",
    "                if itm[5] - itm[3] > 250:\n",
    "                    if not itm[2] in once_seen_droplet:\n",
    "                        once_seen_droplet.append(itm[2])\n",
    "                    elif itm[2] not in twice_seen_droplet:\n",
    "                        twice_seen_droplet.append(itm[2])\n",
    "                        \n",
    "                        # Store the droplet and his cells in new_annot\n",
    "                        new_annot.append(itm)\n",
    "                        # Look at cells in this droplet\n",
    "                        for j in range(0, len(tmp)):\n",
    "                            if tmp[j][1] == 'cell':\n",
    "                                center_x = int((tmp[j][5] + tmp[j][3]) / 2)\n",
    "                                center_y = int((tmp[j][6] + tmp[j][4]) / 2)\n",
    "                                if center_x <= itm[5] and center_x >= itm[3]:\n",
    "                                    if center_y <= itm[6] and center_y >= itm[4]:\n",
    "                                        new_annot.append(tmp[j])\n",
    "                        \n",
    "    # ================================================= #\n",
    "    #      Compare predictions and targets              #\n",
    "    # ================================================= #\n",
    "    # Convert pred dataset\n",
    "    new_pred = convert_pred(preds)\n",
    "    max_pred_slice = int(preds.iloc[preds.shape[0]-1][0].replace('frame_', ''))\n",
    "    \n",
    "    for i in range(0, max(max_pred_slice, max_slice)):\n",
    "        \n",
    "        # Get indexes in the results array if exists\n",
    "        pred_idx = get_result_idx(i, new_pred)\n",
    "        trg_idx = get_result_idx(i, new_annot)\n",
    "        \n",
    "        # Get false positive:\n",
    "        if pred_idx != -1 and trg_idx == -1:\n",
    "            drp_false_positive += 1\n",
    "        # Get false negative\n",
    "        elif pred_idx == -1 and trg_idx != -1:\n",
    "            drp_false_negative += 1\n",
    "        else:\n",
    "            drp_true_positive += 1\n",
    "            \n",
    "            # Now for the cells in this droplet\n",
    "            # Get following cells (associated with this droplet)\n",
    "            pred_cells = []\n",
    "            idx = pred_idx\n",
    "            while idx + 1 < len(new_pred):\n",
    "                idx += 1\n",
    "                if new_pred[idx][1] == 'cell':\n",
    "                    pred_cells.append(new_pred[idx])\n",
    "                else:\n",
    "                    break\n",
    "            trg_cells = []\n",
    "            idx = trg_idx\n",
    "            while idx + 1 < len(new_annot):\n",
    "                idx += 1\n",
    "                if new_annot[idx][1] == 'cell':\n",
    "                    trg_cells.append(new_annot[idx])\n",
    "                else:\n",
    "                    break\n",
    "            # Get true positives and false negatives\n",
    "            #print(len(pred_cells), len(trg_cells))\n",
    "            if len(trg_cells) >= len(pred_cells):\n",
    "                cell_true_positive += len(pred_cells)\n",
    "                cell_false_negative += len(trg_cells) - len(pred_cells)\n",
    "            elif len(trg_cells) < len(pred_cells):\n",
    "                cell_true_positive += len(trg_cells)\n",
    "                cell_false_positive += len(pred_cells) - len(trg_cells)\n",
    "               \n",
    "\n",
    "print('* Droplets results: ')\n",
    "print('*   - True positives: {}'.format(drp_true_positive))\n",
    "print('*   - False positives: {}'.format(drp_false_positive))\n",
    "print('*   - False negatives: {}'.format(drp_false_negative))\n",
    "print('* Cells results: ')\n",
    "print('*   - True positives: {}'.format(cell_true_positive))\n",
    "print('*   - False positives: {}'.format(cell_false_positive))\n",
    "print('*   - False negatives: {}'.format(cell_false_negative))\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16218d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
